{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "(1)hidden_size: output dimension \n",
    "\n",
    "-> result of hidden_state: h_t.shape = (hidden_size, 1)\n",
    "\n",
    "(2)vstack: stack in row direction\n",
    "\n",
    " -> rsult of vstack: concat_vector.shape = (input_size + hidden_size , 1)\n",
    "\n",
    "* but it can only same size col.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activation_function:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "class LSTM(activation_function):\n",
    "    def __init__(self, hidden_size, concat_size):\n",
    "        # z  = alpha(w @ [h, x] + b) \n",
    "        # alpha = activation function\n",
    "        self.w_f = np.random.randn(hidden_size, concat_size)\n",
    "        self.b_f = np.zeros((hidden_size, 1))\n",
    "        self.w_o = np.random.randn(hidden_size, concat_size)\n",
    "        self.b_o = np.zeros((hidden_size, 1))\n",
    "        self.w_c = np.random.randn(hidden_size, concat_size)\n",
    "        self.b_c = np.zeros((hidden_size, 1))\n",
    "        self.w_i = np.random.randn(hidden_size, concat_size)\n",
    "        self.b_i = np.zeros((hidden_size, 1))\n",
    "    \n",
    "    def forget_gate(self, concat_vector):\n",
    "        value = (self.w_f @ concat_vector) + self.b_f\n",
    "        f_t = self.sigmoid(value)\n",
    "        return f_t\n",
    "    \n",
    "    def input_gate(self, concat_vector):\n",
    "        value = (self.w_i @ concat_vector) + self.b_i\n",
    "        i_t = self.sigmoid(value)\n",
    "        return i_t\n",
    "    \n",
    "    def candidate_memory(self, concat_vector):\n",
    "        value = (self.w_c @ concat_vector) + self.b_c\n",
    "        c_t_hat = np.tanh(value)\n",
    "        return c_t_hat\n",
    "    \n",
    "    def output_gate(self ,concat_vector):\n",
    "        value = (self.w_o @ concat_vector) + self.b_o\n",
    "        o_t = self.sigmoid(value)\n",
    "        return o_t\n",
    "\n",
    "    def cell_state_update(self, c_prev ,concat_vector):\n",
    "        c_t_hat = self.candidate_memory(concat_vector)\n",
    "        f_t = self.forget_gate(concat_vector)\n",
    "        i_t = self.input_gate(concat_vector)\n",
    "        c_t = (f_t * c_prev) + (i_t * c_t_hat)\n",
    "        return c_t\n",
    "    \n",
    "    #print summarized information\n",
    "    def hidden_state(self, c_t, concat_vector):\n",
    "        h_t = self.output_gate(concat_vector) * np.tanh(c_t)\n",
    "        return h_t\n",
    "    \n",
    "    def forward(self, concat_vector, h_prev, x_t , c_prev):\n",
    "        concat_vector = np.vstack((h_prev, x_t))\n",
    "        c_t = self.cell_state_update(c_prev, concat_vector)\n",
    "        h_t = self.hidden_state(c_t, concat_vector)\n",
    "        return h_t, c_t\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example_data_set\n",
    "\n",
    "(1)lstm only get 3_dimension data_set\n",
    "    \n",
    "    -> we need to data process\n",
    "\n",
    "(2) because data is just an array of numbers,\n",
    "\n",
    "* we need to create a rule to input into lstm.\n",
    "\n",
    "    def create_sequences divides an array of numbers into time_steps,\n",
    "\n",
    "    and creates multiple samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3) (7,)\n"
     ]
    }
   ],
   "source": [
    "train_set = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "test_set = [1, 2, 3, 4, 5, 6]\n",
    "train_set = np.array(train_set)\n",
    "test_set = np.array(test_set)\n",
    "\n",
    "def create_sequences(data, time_steps =3):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - time_steps): #10 - 3 = 7\n",
    "        seq_x = data[i:i + time_steps]\n",
    "        #0~6, 1~7, 2~8, 3~9, 4~10 (sample)\n",
    "        seq_y = data[i + time_steps]\n",
    "        #7, 8, 9, 10 (correct label)\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "#==================make matrix==================\n",
    "train_data_x , train_data_y = create_sequences(train_set)\n",
    "#==================check data shape=============\n",
    "print(train_data_x.shape, train_data_y.shape)\n",
    "\n",
    "#==================reshape 3_dimension==========\n",
    "train_data_x = train_data_x.reshape((train_data_x.shape[0], train_data_x.shape[1], 1))\n",
    "print(train_data_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_c = LSTM(16 , 26)\n",
    "for i in train_data:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
